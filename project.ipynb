import requests
import twitter
import json
import pandas as pd
import plotly 
# def oauth_login is learned from <<Mining the Social Web, 3rd>>


def oauth_login():
    CONSUMER_KEY = '7a1pq6oCaqGBjp7xoSJ9Hxy3r'
    CONSUMER_SECRET = 'YyDmo9nYgdQ5YeK8zOhfAXsaIoDrU08xAOxzt7vBuUNVMnDldY'
    OAUTH_TOKEN = '1096083516071260162-vFP8ZA9TvVCxlG0haeIyNelOiXt8Zb'
    OAUTH_TOKEN_SECRET = 'Mvkzy8CE8bDKlltZVvqnUhOKvwqDbysdfXlNiKxWui4zQ'
    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,CONSUMER_KEY, CONSUMER_SECRET)
    twitter_api = twitter.Twitter(auth=auth)
    return twitter_api
twitter_api = oauth_login()

#name_list = ['Donald Trump']
name_candidate = input("Enter a candidate's name:")
def candidate(name_candidate):
    name_list= ['Donald Trump','COVID-19','coronavirus']
    for key_word in name_list:
        count = 100
        search_results = twitter_api.search.tweets(q=key_word, count=count, geocode='40.712776,-74.005974,20mi')['statuses']
    # statuses stand for tweets in Twitter. We only filter tweets not the metadata, so by referring ['statuses']ã€‚
    # we didn't save the unwanted data.
        if key_word == name_candidate :
            print('Data for %s: ' %name_candidate)
            tweets = [(r['text'], r['created_at']) for r in search_results]
            texts = [(r['text']) for r in search_results]
            Total_n = len(texts)# the total number of tweets about Trump  
    return tweets, texts, Total_n
#candidate(name_candidate)
#print(candidate(name_candidate))\

def sentimentAnalysis(texts):
    url = 'http://text-processing.com/api/sentiment/'
    positive = 0
    negative = 0
    neutral = 0
    for text in texts:
        options = {'text': text}
        response = requests.post(url, data=options)
        sentiment = response.json()
        if sentiment['label'] == 'neg':
            negative += 1
        elif sentiment['label'] == 'neutral':
            neutral += 1
        elif sentiment['label'] == 'pos':
            positive += 1
    return [positive, neutral, negative]
